# Inference Pipeline

**Production-ready escalation prediction for OSINT article text**

## Overview

This document describes the new inference-only pipeline that replaces the legacy training infrastructure. The new system provides a clean, efficient interface for predicting escalation likelihood from raw article text.

## Quick Start

```python
# Single prediction
from inference_pipeline import predict_escalation
score = predict_escalation("Taiwan military conducts exercises near strait")
print(f"Escalation score: {score:.4f}")
```

```bash
# Batch processing
python inference_pipeline.py input.csv output.csv
```

## Features

- **Tag-based feature extraction** - Compatible with existing XGBoost models
- **Text preprocessing** - Automatic keyword detection and feature engineering
- **Batch processing** - CLI support for CSV files
- **Error handling** - Graceful degradation on invalid input
- **Logging** - Comprehensive logging for monitoring and debugging

## Usage

### Single Predictions

```python
from inference_pipeline import predict_escalation

# Analyze article text
text = """
Taiwan's military conducted large-scale exercises near the Taiwan Strait today, 
prompting China to respond with its own naval maneuvers in the region.
"""

score = predict_escalation(text)
# Returns: float between 0.0 and 1.0
```

### Batch Processing

Input CSV format:
```csv
id,title,text
1,"Military Exercise","Taiwan conducts naval drills..."
2,"Trade Agreement","New economic partnership signed..."
```

```bash
python inference_pipeline.py articles.csv predictions.csv
```

Output CSV includes an additional `escalation_score` column.

### Risk Classification

- **High Risk** (> 0.7): Strong indicators of potential escalation
- **Medium Risk** (0.3 - 0.7): Some escalatory elements detected  
- **Low Risk** (â‰¤ 0.3): Minimal escalation indicators

## Model Information

- **Current Model**: XGBoost classifier trained on conflict indicators
- **Features**: 7 tag-based features + confidence score (8 total)
- **Tags**: military movement, conflict, cyberattack, protest, diplomatic meeting, nuclear, ceasefire
- **Fallback**: Automatically selects latest available model from `models/` directory

## Integration Points

This pipeline is designed to be used by:

- **Daily clustering systems** - Score articles for grouping
- **Digest generation** - Prioritize high-risk content
- **Streamlit dashboards** - Real-time risk assessment
- **Auto-alert systems** - Trigger notifications
- **Batch processing jobs** - Analyze historical data

## Testing

```bash
# Run all tests
python -m pytest tests/test_inference_pipeline.py -v

# Test with sample data
python inference_pipeline.py
```

## Legacy Code Cleanup

As part of this upgrade, the following legacy files have been cleaned up:

### Commented Out / Deprecated

- `conflict_model_training.py` - ACLED/GDELT/UCDP training logic
- `fetch_peaceful_events.py` - GDELT peaceful event extraction
- `fetch_and_clean_data.py` - Multi-source dataset merging

### Reason for Cleanup

The original training infrastructure relied on:
- Manual conflict label alignment across ACLED, GDELT, and UCDP
- External geoparsing and CSV label propagation
- Complex dataset merging and preprocessing
- Outdated feature engineering approaches

This has been replaced with a simpler, more maintainable approach focused on inference.

## Migration Guide

### Old Approach
```python
# Legacy - required dataset preparation
from conflict_model_training import train_xgboost
from fetch_and_clean_data import create_unified_dataset
# Complex multi-step training process...
```

### New Approach
```python
# Modern - direct inference
from inference_pipeline import predict_escalation
score = predict_escalation("article text")
```

### For Developers

If you need to train new models, consider:

1. **Use the inference pipeline interface** - Keep the same `predict_escalation()` API
2. **Modern ML approaches** - Consider transformer-based models
3. **Simpler feature engineering** - Direct text-to-prediction without complex preprocessing
4. **Version control** - Use semantic versioning for model files

## Performance

- **Latency**: ~100-200ms per prediction (includes model loading)
- **Throughput**: Batch processing handles 100+ articles efficiently
- **Memory**: Minimal memory footprint with lazy model loading
- **Accuracy**: Maintains compatibility with existing model performance

## Monitoring

The pipeline provides comprehensive logging:

```
INFO - Loading classifier from: models/xgboost_conflict_model_20250519.pkl
INFO - Processing 150 articles...
INFO - Summary: 5 high-risk, 23 medium-risk, 122 low-risk articles
```

Monitor these logs in production for:
- Model loading issues
- Processing performance
- Risk distribution trends

## Support

For issues or questions:
1. Check the test suite for usage examples
2. Review the docstrings in `inference_pipeline.py`
3. Examine the legacy code comments for context on replaced functionality 